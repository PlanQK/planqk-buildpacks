# Why Buildpacks

Status qou was that:

users of the platform can have their projects processed as Docker images. This currently requires a Conda environment and an environment.yml as well as a Dockerfile. To enable more flexibility, pip and poetry will also be supported. In addition, the process can be serialized and simplified with buildpacks. The users then no longer need a docker file and can continue to use their resources for our platform. With the buildpacks, we can set up the platform more broadly. They are variable and can be extended to languages other than Python if required. They reduce barriers and enable faster and direct access to quantum computing without having to deal with Docker.

# will be named soon

A builder.toml is required to create a buildpack. All information required for the necessary buildpacks must be in the correct order in the .toml.  A buildpack image is then generated from this. [builder.toml docs](https://buildpacks.io/docs/reference/config/builder-config/)
This builder image then generates OCI images from an app template. At the moment the Python and the Procfile buildpack from Paketo are used for the necessary requirements. A profile is required to be able to determine the container's entry point in the future.  
* The Procfile is always a simple text file that is named Procfile without a file extension. For example, Procfile. txt is not valid. The Procfile must live in your app's root directory.


# Process flow 

All the user has to do is upload a zip file with their code to the platform. The rest happens in the background for the user. 

To execute a user job, the project is copied into a serverless template. The template contains a run method and all necessary implementations to process the data of the job. This run method calls the user code. This is necessary to create as few barriers as possible for the user and to minimize sources of error.  



```bash
serverless-template/
├── job-template/
│   ├── app/
│   │    ├──user-code
│   │    └──...
│   ├── tests/
│   └── ...
├── dockerfile-template/
│   │   └── ...
└── ...

 ```
The build process of the buildpack then starts at the level of the job-template directory. This directory then becomes the first app level in the docker image. The files for the requirements must be saved in this directory. The required profile is also saved in this location. 

wo geht der user code hin 

das template wird als Service mit einer ID gespeichert
via planqk run wird dieser Service den ausgeführt?

was passiert danach 


However, the use of buildpacks results in changes. The requirements were previously stored in the user-code directory. These must now be saved at the job-template directory. Instead of the Dockerfile, a Procfile is now required to start the app. When building the container, the docker engine only looks at the root directory of the image for necessary environmental conditions. Procfile and all requirements must be saved here. It is no longer possible to have a requirements.txt and an environment.yml in the same directory.  This is because the buildpack will always use pip first. If a conda environment is desired, no requirements.txt must be present. 




# Creating and using a Python builder - an example

Cloud native buildpacks provide their own CLI. This can be obtained from their website: [pack CLI](https://buildpacks.io/docs/tools/pack/#install).  
The pack CLI and Docker are required for the example process. 

More information can be read on the [website](https://buildpacks.io/docs/concepts/) from CLoud Native Buildpacks.

To build a builder, the Docker engine must be running. 

```bash

git clone https://github.com/PlanQK/planqk-buildpacks
cd planqk-buildpacks\planqk-base
pack builder create planqk-base-builder --config .\builder.toml

```
A Python builder has now been created.  
There is a test app to test whether the builder works. 

```bash

cd..
cd conda/sample
pack build my_testapp --builder planqk-base-builder

```
The builder has built an OCI image from the app. Docker is required to start it. 

```bash

 docker run -it -e PORT=8080 -p 8080:8080 my_testapp

```
Localhost:8080 can now be opened in the browser.




# starting a job with buildpacks

```bash
git clone https://gitlab.com/StoneOne/planqk/serverless-template.git
cd serverless-template/job-template/app
planqk init
mv <directory-name> user-code # The directory name is the name randomly generated by planqk init
cd..
```
The current directory should now be the job-template directory

```bash
cp app/user-code/requirements.txt .
touch Procfile
nano Procfile
web: python -m app
'Crtl + 0'
'Crtl + X'
```

There must only be a requirements.txt OR an environment.yml in the directory. If present, the environment.yml must be deleted. The docker engine must also be running.
Now all preparations are completed and the template can be built into an image.

```bash

pack build user-service --builder planqk-base-builder
```


* go to job template layer
* check for requirements.txt OR environment.yml at the job template layer 
* check for procfile
* start building process


* problems : As the build process is started at job-template level, the requirements must also be saved there. However, these come from the user code and must then be moved from there. This makes an additional implementation necessary.


* docker run, path for json must be correct!
* PROJECT_ROOT=(`pwd`)  must be correct, too
```bash
PROJECT_ROOT=(`pwd`) 
docker run -it \
  -e BASE64_ENCODED=false \
  -v $PROJECT_ROOT/app/user_code/input/data.json:/var/input/data.json \
  -v $PROJECT_ROOT/app/user_code/input/params.json:/var/input/params/params.json \
```

